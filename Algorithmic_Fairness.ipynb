{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Algorithmic_Fairness.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60109514-b5a7-413b-88a0-af9e1af8b63b"
      },
      "source": [
        "***\n",
        "## Algorithmic fairness with AI FairnessÂ 360 (IBM)\n",
        "### This notebook is accompanied by a Medium article I wrote, published [here](https://medium.com/@alinedintino/mitigating-bias-and-ensuring-fairness-in-machine-learning-algorithms-a0b77a8f49eb)\n",
        "***"
      ],
      "id": "60109514-b5a7-413b-88a0-af9e1af8b63b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKlA-R0ApEnA"
      },
      "source": [
        "# Load all necessary packages\n",
        "import pandas as pd\n",
        "import aif360\n",
        "from aif360.datasets import GermanDataset\n",
        "from aif360.algorithms.preprocessing.lfr import LFR\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "id": "cKlA-R0ApEnA",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "hYOyQMDSwLSa",
        "outputId": "9e895e7f-6c1a-4812-d092-242976d39c77"
      },
      "source": [
        "# Read the GermanDataset\n",
        "german_data = GermanDataset()\n",
        "german_df = german_data.convert_to_dataframe()\n",
        "german_df = german_df[0]\n",
        "german_df.head()"
      ],
      "id": "hYOyQMDSwLSa",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>investment_as_income_percentage</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>number_of_credits</th>\n",
              "      <th>people_liable_for</th>\n",
              "      <th>sex</th>\n",
              "      <th>status=A11</th>\n",
              "      <th>status=A12</th>\n",
              "      <th>status=A13</th>\n",
              "      <th>status=A14</th>\n",
              "      <th>credit_history=A30</th>\n",
              "      <th>credit_history=A31</th>\n",
              "      <th>credit_history=A32</th>\n",
              "      <th>credit_history=A33</th>\n",
              "      <th>credit_history=A34</th>\n",
              "      <th>purpose=A40</th>\n",
              "      <th>purpose=A41</th>\n",
              "      <th>purpose=A410</th>\n",
              "      <th>purpose=A42</th>\n",
              "      <th>purpose=A43</th>\n",
              "      <th>purpose=A44</th>\n",
              "      <th>purpose=A45</th>\n",
              "      <th>purpose=A46</th>\n",
              "      <th>purpose=A48</th>\n",
              "      <th>purpose=A49</th>\n",
              "      <th>savings=A61</th>\n",
              "      <th>savings=A62</th>\n",
              "      <th>savings=A63</th>\n",
              "      <th>savings=A64</th>\n",
              "      <th>savings=A65</th>\n",
              "      <th>employment=A71</th>\n",
              "      <th>employment=A72</th>\n",
              "      <th>employment=A73</th>\n",
              "      <th>employment=A74</th>\n",
              "      <th>employment=A75</th>\n",
              "      <th>other_debtors=A101</th>\n",
              "      <th>other_debtors=A102</th>\n",
              "      <th>other_debtors=A103</th>\n",
              "      <th>property=A121</th>\n",
              "      <th>property=A122</th>\n",
              "      <th>property=A123</th>\n",
              "      <th>property=A124</th>\n",
              "      <th>installment_plans=A141</th>\n",
              "      <th>installment_plans=A142</th>\n",
              "      <th>installment_plans=A143</th>\n",
              "      <th>housing=A151</th>\n",
              "      <th>housing=A152</th>\n",
              "      <th>housing=A153</th>\n",
              "      <th>skill_level=A171</th>\n",
              "      <th>skill_level=A172</th>\n",
              "      <th>skill_level=A173</th>\n",
              "      <th>skill_level=A174</th>\n",
              "      <th>telephone=A191</th>\n",
              "      <th>telephone=A192</th>\n",
              "      <th>foreign_worker=A201</th>\n",
              "      <th>foreign_worker=A202</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1169.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.0</td>\n",
              "      <td>5951.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.0</td>\n",
              "      <td>2096.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42.0</td>\n",
              "      <td>7882.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24.0</td>\n",
              "      <td>4870.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   month  credit_amount  ...  foreign_worker=A202  credit\n",
              "0    6.0         1169.0  ...                  0.0     1.0\n",
              "1   48.0         5951.0  ...                  0.0     2.0\n",
              "2   12.0         2096.0  ...                  0.0     1.0\n",
              "3   42.0         7882.0  ...                  0.0     1.0\n",
              "4   24.0         4870.0  ...                  0.0     2.0\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVY-qBXTxyrP"
      },
      "source": [
        "# Define the privileged and unprivileged groups\n",
        "privileged_groups = [{'sex': 1,'age': 1}]\n",
        "unprivileged_groups = [{'sex': 0,'age': 0}] \n",
        "\n",
        "#privileged_groups = [{'sex': 1}]\n",
        "#unprivileged_groups = [{'sex': 0}]"
      ],
      "id": "TVY-qBXTxyrP",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dWBnAdEocJj",
        "outputId": "9e79021f-fb98-4aa7-86bd-ad527a09e5ac"
      },
      "source": [
        "# Fairness performance of datasets before classification\n",
        "# Constucting two functions to call the desired metrics\n",
        "metric_orig = BinaryLabelDatasetMetric(german_data, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Disparate impact (of original labels) between unprivileged and privileged groups = %f\" % metric_orig.disparate_impact())\n",
        "print(\"Difference in statistical parity (of original labels) between unprivileged and privileged groups = %f\" % metric_orig.statistical_parity_difference())\n",
        "print(\"Individual fairness metric that measures how similar the labels are for similar instances = %f\" % metric_orig.consistency())"
      ],
      "id": "8dWBnAdEocJj",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate impact (of original labels) between unprivileged and privileged groups = 0.747630\n",
            "Difference in statistical parity (of original labels) between unprivileged and privileged groups = -0.186462\n",
            "Individual fairness metric that measures how similar the labels are for similar instances = 0.681600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73PhgpAcvD7M",
        "outputId": "6615b54d-83b2-4188-fe60-08f6317c60dd"
      },
      "source": [
        "# Baseline Method \n",
        "dataset_orig_train, dataset_orig_test = german_data.split([0.7], shuffle=True)\n",
        "\n",
        "# Using Learning fair representations (LFR) to transform german dataset\n",
        "# Required Inputs:\n",
        "# Input recontruction quality - Ax\n",
        "# Fairness constraint - Az\n",
        "# Output prediction error - Ay\n",
        "\n",
        "# Scaling the dataset (scaled dataset together with its labels is needed)\n",
        "scale_orig = StandardScaler()\n",
        "dataset_orig_train.features = scale_orig.fit_transform(dataset_orig_train.features)\n",
        "dataset_orig_test.features = scale_orig.transform(dataset_orig_test.features)\n",
        "\n",
        "# LFR itself contains logistic regression sync, it uses sigmoid functions \n",
        "LFR = LFR(unprivileged_groups=unprivileged_groups,\n",
        "         privileged_groups=privileged_groups,\n",
        "         k=5, Ax=0.1, Ay=1.0, Az=100.0, verbose=1)\n",
        "\n",
        "TR = LFR.fit(dataset_orig_train, maxiter=5000, maxfun=5000)\n",
        "\n",
        "# Transform training data and align features\n",
        "dataset_transf_train = TR.transform(dataset_orig_train)"
      ],
      "id": "73PhgpAcvD7M",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss: 2.963634337314576, L_x: 2.5346566554093064,  L_y: 0.9067669031489546,  L_z: 0.018034017686246913\n",
            "step: 250, loss: 2.9636344073686245, L_x: 2.5346566987843238,  L_y: 0.9067669430305679,  L_z: 0.01803401794459624\n",
            "step: 500, loss: 1.1706940521058324, L_x: 2.5402542723784203,  L_y: 0.3581552322727513,  L_z: 0.00558513392595239\n",
            "step: 750, loss: 0.9420320974136516, L_x: 2.540430188565174,  L_y: 0.1550320667578237,  L_z: 0.0053295701179931045\n",
            "step: 1000, loss: 0.6659995683788107, L_x: 2.5414980142049233,  L_y: -0.07263891355174788,  L_z: 0.004844886805100662\n",
            "step: 1250, loss: 0.21060397314217416, L_x: 2.542904017329769,  L_y: -0.6581765260467153,  L_z: 0.006144900974559125\n",
            "step: 1500, loss: -0.09507425696286814, L_x: 2.542694942480411,  L_y: -0.797484418211194,  L_z: 0.004481406670002847\n",
            "step: 1750, loss: -0.09507465451654312, L_x: 2.5426949875874882,  L_y: -0.7974842905855608,  L_z: 0.004481401373102689\n",
            "step: 2000, loss: -0.4248344053658831, L_x: 2.5424705616201573,  L_y: -0.9737579961974663,  L_z: 0.0029467653466956735\n",
            "step: 2250, loss: -0.6448246642828694, L_x: 2.54201434592109,  L_y: -1.1030788068897999,  L_z: 0.0020405270801482135\n",
            "step: 2500, loss: -9.719523342382148, L_x: 2.5370785586195717,  L_y: -11.070440001029674,  L_z: 0.010972088027855681\n",
            "step: 2750, loss: 28.18084395787314, L_x: 389.4050281126738,  L_y: -10.773117795841676,  L_z: 0.00013458942447437843\n",
            "step: 3000, loss: 0.37653471489736656, L_x: 105.62288552476403,  L_y: -10.830302934025715,  L_z: 0.006445490964466787\n",
            "step: 3250, loss: 0.36103991869898944, L_x: 105.62288577471168,  L_y: -10.845797765151945,  L_z: 0.006445491063797657\n",
            "step: 3500, loss: -5.5925090481791475, L_x: 15.016196750952464,  L_y: -10.926303236081031,  L_z: 0.03832174512806637\n",
            "step: 3750, loss: -7.3048184635173925, L_x: 5.1794635992851905,  L_y: -11.018140450743171,  L_z: 0.031953756272972596\n",
            "step: 4000, loss: -8.53905064936025, L_x: 3.490371111843324,  L_y: -11.032242277750465,  L_z: 0.02144154517205882\n",
            "step: 4250, loss: -9.236383836373973, L_x: 2.866892982634951,  L_y: -11.0602134117266,  L_z: 0.01537140277089133\n",
            "step: 4500, loss: -9.548221438454677, L_x: 2.6483438647796236,  L_y: -11.080941024664876,  L_z: 0.012678851997322365\n",
            "step: 4750, loss: -9.674780916579452, L_x: 2.567534241866358,  L_y: -11.078172862690803,  L_z: 0.011466385219247149\n",
            "step: 5000, loss: -9.661981360805916, L_x: 2.5675342686504576,  L_y: -11.06537425419981,  L_z: 0.011466394665288487\n",
            "step: 5250, loss: -9.70068246810801, L_x: 2.546039357861437,  L_y: -11.067267228024027,  L_z: 0.011119808241298745\n",
            "step: 5500, loss: -9.709415621416257, L_x: 2.5400818915820427,  L_y: -11.065605584010019,  L_z: 0.011021817734355566\n",
            "step: 5750, loss: -9.718774751115204, L_x: 2.538165367358735,  L_y: -11.071598799335062,  L_z: 0.010990075114839843\n",
            "step: 6000, loss: -9.730293177269008, L_x: 2.5375211584409154,  L_y: -11.081989225489911,  L_z: 0.010979439323768103\n",
            "step: 6250, loss: -9.708859286970423, L_x: 2.537234713449406,  L_y: -11.06005086046886,  L_z: 0.01097468102153496\n",
            "step: 6500, loss: -9.716868939734677, L_x: 2.5372347582465027,  L_y: -11.068060315792007,  L_z: 0.010974679002326793\n",
            "step: 6750, loss: -9.723494943793725, L_x: 2.5371357647101833,  L_y: -11.074512725135833,  L_z: 0.010973042048710895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7EUnLW3viCP",
        "outputId": "93dd17ad-12b7-4b67-dc54-df6301a4a112"
      },
      "source": [
        "# Check if the labels are transformed: counts the num. of transformed labels\n",
        "k=0\n",
        "for i in range(len(dataset_orig_train.labels)):\n",
        "    if(dataset_transf_train.labels[i] == dataset_orig_train.labels[i]):\n",
        "        pass\n",
        "    else:\n",
        "        k+=1\n",
        "        \n",
        "k"
      ],
      "id": "c7EUnLW3viCP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "216"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwaXwdXvkyy",
        "outputId": "a1604a54-0a53-400a-cdac-268c27c2f0eb"
      },
      "source": [
        "# Measuring fairness performance again\n",
        "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups)\n",
        "\n",
        "print(\"Disparate impact ratio (of transformed labels) between unprivileged and privileged groups = %f\" % metric_transf_train.disparate_impact())\n",
        "print(\"Difference in statistical parity (of transformed labels) between unprivileged and privileged groups = %f\" % metric_transf_train.statistical_parity_difference())\n",
        "print(\"Individual fairness metric 'consistency' that measures how similar the labels are for similar instances = %f\" % metric_transf_train.consistency())"
      ],
      "id": "XcwaXwdXvkyy",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate impact ratio (of transformed labels) between unprivileged and privileged groups = 1.000000\n",
            "Difference in statistical parity (of transformed labels) between unprivileged and privileged groups = 0.000000\n",
            "Individual fairness metric 'consistency' that measures how similar the labels are for similar instances = 1.000000\n"
          ]
        }
      ]
    }
  ]
}